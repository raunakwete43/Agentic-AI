{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "71b4bab6",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_openai import ChatOpenAI\n",
    "from dotenv import load_dotenv\n",
    "import os\n",
    "from rich.pretty import pprint\n",
    "from rich.markdown import Markdown\n",
    "\n",
    "load_dotenv()\n",
    "\n",
    "\n",
    "MODEL = os.getenv(\"MODEL\", \"gemini-2.5-flash-lite\")\n",
    "BASE_URL = os.getenv(\"BASE_URL\")\n",
    "API_KEY = os.getenv(\"GEMINI_API_KEY\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "e45c3066",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Hi there! How can I help you today?\n"
     ]
    }
   ],
   "source": [
    "llm = ChatOpenAI(\n",
    "    model=MODEL,\n",
    "    base_url=BASE_URL,\n",
    "    api_key=API_KEY,  # type: ignore\n",
    "    temperature=0,\n",
    ")\n",
    "\n",
    "print(llm.invoke(\"Hi!\").content)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "6bae7457",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langgraph.graph import StateGraph, START, END\n",
    "from langchain_core.messages import HumanMessage, SystemMessage\n",
    "\n",
    "from langgraph.types import Send, Command"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "d27bdd31",
   "metadata": {},
   "outputs": [],
   "source": [
    "from typing import TypedDict, Annotated, NotRequired, Literal\n",
    "import operator\n",
    "\n",
    "class AgentState(TypedDict):\n",
    "    topic: str\n",
    "    task: Literal[\"joke\", \"poem\", \"story\"]\n",
    "    prompt: NotRequired[str]\n",
    "    response: NotRequired[str]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "e0099705",
   "metadata": {},
   "outputs": [],
   "source": [
    "def _init_llm(state: AgentState)->Command[Literal[\"generate_response\"]]:\n",
    "    topic = state[\"task\"]\n",
    "    if topic == \"joke\":\n",
    "        prompt = f\"Tell me a joke about {topic}\"\n",
    "    elif topic == \"poem\":\n",
    "        prompt = f\"Write a poem about {topic}\"\n",
    "    elif topic == \"story\":\n",
    "        prompt = f\"Write a short story about {topic}\"\n",
    "\n",
    "    return Command(\n",
    "        update={\"prompt\": prompt},\n",
    "        goto=\"generate_response\",\n",
    "    )\n",
    "\n",
    "def _gen_response(state: AgentState):\n",
    "    response = llm.invoke([HumanMessage(\n",
    "        content=state.get('prompt', '')\n",
    "    )])\n",
    "\n",
    "    return {\"response\": response.content}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "ebd04c44",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    +-----------+      \n",
      "    | __start__ |      \n",
      "    +-----------+      \n",
      "          *            \n",
      "          *            \n",
      "          *            \n",
      "    +----------+       \n",
      "    | init_llm |       \n",
      "    +----------+       \n",
      "          .            \n",
      "          .            \n",
      "          .            \n",
      "+-------------------+  \n",
      "| generate_response |  \n",
      "+-------------------+  \n",
      "          *            \n",
      "          *            \n",
      "          *            \n",
      "     +---------+       \n",
      "     | __end__ |       \n",
      "     +---------+       \n"
     ]
    }
   ],
   "source": [
    "graph = StateGraph(AgentState)\n",
    "\n",
    "graph.add_node(\"generate_response\", _gen_response)\n",
    "graph.add_node(\"init_llm\", _init_llm)\n",
    "\n",
    "graph.add_edge(START, \"init_llm\")\n",
    "\n",
    "graph.add_edge(\"generate_response\", END)\n",
    "\n",
    "agent = graph.compile()\n",
    "print(agent.get_graph().draw_ascii())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "162ae397",
   "metadata": {},
   "outputs": [],
   "source": [
    "response = agent.invoke({\"topic\": \"monsoon\", \"task\": \"joke\"})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "669e54f0",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\">{</span>\n",
       "<span style=\"color: #7fbf7f; text-decoration-color: #7fbf7f\">│   </span><span style=\"color: #008000; text-decoration-color: #008000\">'topic'</span>: <span style=\"color: #008000; text-decoration-color: #008000\">'monsoon'</span>,\n",
       "<span style=\"color: #7fbf7f; text-decoration-color: #7fbf7f\">│   </span><span style=\"color: #008000; text-decoration-color: #008000\">'task'</span>: <span style=\"color: #008000; text-decoration-color: #008000\">'joke'</span>,\n",
       "<span style=\"color: #7fbf7f; text-decoration-color: #7fbf7f\">│   </span><span style=\"color: #008000; text-decoration-color: #008000\">'prompt'</span>: <span style=\"color: #008000; text-decoration-color: #008000\">'Tell me a joke about joke'</span>,\n",
       "<span style=\"color: #7fbf7f; text-decoration-color: #7fbf7f\">│   </span><span style=\"color: #008000; text-decoration-color: #008000\">'response'</span>: <span style=\"color: #008000; text-decoration-color: #008000\">'Why did the joke break up with the punchline?\\n\\nBecause it felt like the punchline was always *telling* it what to do!'</span>\n",
       "<span style=\"font-weight: bold\">}</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m{\u001b[0m\n",
       "\u001b[2;32m│   \u001b[0m\u001b[32m'topic'\u001b[0m: \u001b[32m'monsoon'\u001b[0m,\n",
       "\u001b[2;32m│   \u001b[0m\u001b[32m'task'\u001b[0m: \u001b[32m'joke'\u001b[0m,\n",
       "\u001b[2;32m│   \u001b[0m\u001b[32m'prompt'\u001b[0m: \u001b[32m'Tell me a joke about joke'\u001b[0m,\n",
       "\u001b[2;32m│   \u001b[0m\u001b[32m'response'\u001b[0m: \u001b[32m'Why did the joke break up with the punchline?\\n\\nBecause it felt like the punchline was always *telling* it what to do!'\u001b[0m\n",
       "\u001b[1m}\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "pprint(response)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "301afa25",
   "metadata": {},
   "outputs": [],
   "source": [
    "class AgentState(TypedDict):\n",
    "    messages: NotRequired[Annotated[list, operator.add]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "ad90fa1d",
   "metadata": {},
   "outputs": [],
   "source": [
    "def _init_llm(state: AgentState):\n",
    "    system_prompt = (\n",
    "        \"Your are an helpful chatbot with strong memory and recall capabilities.\"\n",
    "    )\n",
    "    messages = [SystemMessage(content=system_prompt)]\n",
    "\n",
    "    return {\"messages\": messages}\n",
    "\n",
    "\n",
    "def _call_model(state: AgentState):\n",
    "    messages = state.get(\"messages\", [])\n",
    "    response = llm.invoke(messages)\n",
    "    print(\"Assistant response: \", end=\"\")\n",
    "    print(response.content)\n",
    "    messages.append(response)\n",
    "\n",
    "    return {\"messages\": messages}\n",
    "\n",
    "\n",
    "def _should_continue(state: AgentState) -> Command[Literal[\"call_model\", \"__end__\"]]:\n",
    "    user_input = str(input(\"Enter your Query(use `quit` to exit): \"))\n",
    "    if user_input.lower() == \"quit\":\n",
    "        return Command(goto=\"__end__\")\n",
    "    else:\n",
    "        messages = [HumanMessage(content=user_input)]\n",
    "        return Command(update={\"messages\": messages}, goto=\"call_model\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "2df2b966",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "            +-----------+             \n",
      "            | __start__ |             \n",
      "            +-----------+             \n",
      "                   *                  \n",
      "                   *                  \n",
      "                   *                  \n",
      "             +----------+             \n",
      "             | init_llm |             \n",
      "             +----------+             \n",
      "                   *                  \n",
      "                   *                  \n",
      "                   *                  \n",
      "         +-----------------+          \n",
      "         | should_continue |          \n",
      "         +-----------------+          \n",
      "            ***         ...           \n",
      "           *               .          \n",
      "         **                 ..        \n",
      "+------------+           +---------+  \n",
      "| call_model |           | __end__ |  \n",
      "+------------+           +---------+  \n"
     ]
    }
   ],
   "source": [
    "graph = StateGraph(AgentState)\n",
    "\n",
    "graph.add_node(\"init_llm\", _init_llm)\n",
    "graph.add_node(\"call_model\", _call_model)\n",
    "graph.add_node(\"should_continue\", _should_continue)\n",
    "\n",
    "graph.add_edge(START, \"init_llm\")\n",
    "graph.add_edge(\"init_llm\", \"should_continue\")\n",
    "graph.add_edge(\"call_model\", \"should_continue\")\n",
    "\n",
    "agent = graph.compile()\n",
    "print(agent.get_graph().draw_ascii())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "d14b3ea3",
   "metadata": {},
   "outputs": [],
   "source": [
    "response = agent.invoke({})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "de6a7d0f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\">[</span>\n",
       "<span style=\"color: #7fbf7f; text-decoration-color: #7fbf7f\">│   </span><span style=\"color: #800080; text-decoration-color: #800080; font-weight: bold\">SystemMessage</span><span style=\"font-weight: bold\">(</span>\n",
       "<span style=\"color: #7fbf7f; text-decoration-color: #7fbf7f\">│   │   </span><span style=\"color: #808000; text-decoration-color: #808000\">content</span>=<span style=\"color: #008000; text-decoration-color: #008000\">'Your are an helpful chatbot with strong memory and recall capabilities.'</span>,\n",
       "<span style=\"color: #7fbf7f; text-decoration-color: #7fbf7f\">│   │   </span><span style=\"color: #808000; text-decoration-color: #808000\">additional_kwargs</span>=<span style=\"font-weight: bold\">{}</span>,\n",
       "<span style=\"color: #7fbf7f; text-decoration-color: #7fbf7f\">│   │   </span><span style=\"color: #808000; text-decoration-color: #808000\">response_metadata</span>=<span style=\"font-weight: bold\">{}</span>\n",
       "<span style=\"color: #7fbf7f; text-decoration-color: #7fbf7f\">│   </span><span style=\"font-weight: bold\">)</span>\n",
       "<span style=\"font-weight: bold\">]</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m[\u001b[0m\n",
       "\u001b[2;32m│   \u001b[0m\u001b[1;35mSystemMessage\u001b[0m\u001b[1m(\u001b[0m\n",
       "\u001b[2;32m│   │   \u001b[0m\u001b[33mcontent\u001b[0m=\u001b[32m'Your are an helpful chatbot with strong memory and recall capabilities.'\u001b[0m,\n",
       "\u001b[2;32m│   │   \u001b[0m\u001b[33madditional_kwargs\u001b[0m=\u001b[1m{\u001b[0m\u001b[1m}\u001b[0m,\n",
       "\u001b[2;32m│   │   \u001b[0m\u001b[33mresponse_metadata\u001b[0m=\u001b[1m{\u001b[0m\u001b[1m}\u001b[0m\n",
       "\u001b[2;32m│   \u001b[0m\u001b[1m)\u001b[0m\n",
       "\u001b[1m]\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "pprint(response[\"messages\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1d60849d",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "agentic-ai",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
