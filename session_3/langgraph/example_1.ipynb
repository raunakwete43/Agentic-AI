{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "b5ef309d",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_openai import ChatOpenAI\n",
    "from dotenv import load_dotenv\n",
    "import os\n",
    "from rich.pretty import pprint\n",
    "from rich.markdown import Markdown\n",
    "\n",
    "load_dotenv()\n",
    "\n",
    "\n",
    "MODEL = os.getenv(\"MODEL\", \"gemini-2.5-flash-lite\")\n",
    "BASE_URL = os.getenv(\"BASE_URL\")\n",
    "API_KEY = os.getenv(\"GEMINI_API_KEY\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "742bdf65",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Hi there! How can I help you today?\n"
     ]
    }
   ],
   "source": [
    "llm = ChatOpenAI(\n",
    "    model=MODEL,\n",
    "    base_url=BASE_URL,\n",
    "    api_key=API_KEY,  # type: ignore\n",
    "    temperature=0,\n",
    ")\n",
    "\n",
    "print(llm.invoke(\"Hi!\").content)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "6859495f",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langgraph.graph import StateGraph, START, END\n",
    "from langchain_core.messages import HumanMessage, SystemMessage"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a8962572",
   "metadata": {},
   "outputs": [],
   "source": [
    "s"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "4ff4e99f",
   "metadata": {},
   "outputs": [],
   "source": [
    "def _init_llm(state: AgentState):\n",
    "    system_prompt = (\n",
    "        \"Your are an helpful chatbot with strong memory and recall capabilities.\"\n",
    "    )\n",
    "    messages = [SystemMessage(content=system_prompt)]\n",
    "\n",
    "    return {\"messages\": messages}\n",
    "\n",
    "\n",
    "def _call_model(state: AgentState):\n",
    "    user_msg = str(input(\"Enter your query: \"))\n",
    "    messages = []\n",
    "    messages.append(HumanMessage(content=user_msg))\n",
    "    response = llm.invoke(messages)\n",
    "    print(\"Assistant response: \", end=\"\")\n",
    "    print(response.content)\n",
    "    messages.append(response)\n",
    "\n",
    "    return {\"messages\": messages}\n",
    "\n",
    "def _should_continue(state: AgentState):\n",
    "    user_input = str(input(\"Do you want to continue? (y/n): \"))\n",
    "    if user_input.lower() == 'y':\n",
    "        return \"call_model\"\n",
    "    else:\n",
    "        return END\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "f3017aec",
   "metadata": {},
   "outputs": [],
   "source": [
    "graph = StateGraph(AgentState)\n",
    "\n",
    "graph.add_node(\"init_llm\", _init_llm)\n",
    "graph.add_node(\"call_model\", _call_model)\n",
    "\n",
    "graph.add_edge(START, \"init_llm\")\n",
    "graph.add_edge(\"init_llm\", \"call_model\")\n",
    "graph.add_conditional_edges(\"call_model\", _should_continue)\n",
    "\n",
    "agent = graph.compile()\n",
    "# agent"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "f485c1e1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Assistant response: Hi Raunak! It's nice to meet you. How can I help you today?\n",
      "Assistant response: Gemini is a **family of large language models (LLMs)** developed by **Google AI**. Think of it as a highly advanced AI system designed to understand and generate human-like text, and increasingly, to process and reason about other types of information like code, images, audio, and video.\n",
      "\n",
      "Here's a breakdown of what that means and what makes Gemini significant:\n",
      "\n",
      "**Key Characteristics of Gemini:**\n",
      "\n",
      "*   **Multimodal:** This is a core differentiator. Gemini is designed from the ground up to be multimodal, meaning it can understand and operate across different types of information simultaneously. This allows it to:\n",
      "    *   **Understand text and code:** Like many LLMs, it can write, translate, answer questions, and summarize text. It's also proficient in various programming languages.\n",
      "    *   **Process images:** It can analyze images, describe their content, answer questions about them, and even generate captions.\n",
      "    *   **Understand audio and video:** While still evolving, Gemini is being developed to process and reason about audio and video content, opening up possibilities for more complex interactions.\n",
      "\n",
      "*   **Designed for Scale and Efficiency:** Gemini comes in different sizes, optimized for various tasks and devices:\n",
      "    *   **Gemini Ultra:** The largest and most capable model, designed for highly complex tasks.\n",
      "    *   **Gemini Pro:** A versatile model that balances capability with efficiency, suitable for a wide range of applications.\n",
      "    *   **Gemini Nano:** The most efficient model, designed to run directly on mobile devices, enabling on-device AI experiences.\n",
      "\n",
      "*   **Advanced Reasoning Capabilities:** Gemini aims to go beyond simple pattern matching. It's designed to:\n",
      "    *   **Reason logically:** It can follow complex instructions and perform multi-step reasoning.\n",
      "    *   **Understand context:** It can grasp the nuances of conversations and information.\n",
      "    *   **Solve problems:** It can be applied to a variety of problem-solving scenarios.\n",
      "\n",
      "*   **Built for Integration:** Gemini is intended to be integrated into a wide range of Google products and services, as well as made available to developers through APIs. This means you'll likely encounter Gemini powering features in:\n",
      "    *   **Google Search:** Enhancing search results and providing more conversational answers.\n",
      "    *   **Google Workspace:** Assisting with writing, summarizing, and analyzing documents, emails, and spreadsheets.\n",
      "    *   **Google Cloud:** Providing AI capabilities for businesses and developers.\n",
      "    *   **Android devices:** Enabling new on-device AI features.\n",
      "\n",
      "**Why is Gemini Important?**\n",
      "\n",
      "Gemini represents a significant step forward in AI development for several reasons:\n",
      "\n",
      "*   **True Multimodality:** Its native multimodal design is a key advancement, allowing for more holistic understanding and interaction with the world.\n",
      "*   **Performance:** Google claims Gemini Ultra outperforms existing state-of-the-art models on many benchmarks, particularly in multimodal reasoning.\n",
      "*   **Accessibility:** The different model sizes make advanced AI accessible across a spectrum of devices and applications.\n",
      "*   **Future of AI:** It's positioned as a foundational technology for future AI advancements and applications.\n",
      "\n",
      "**In simpler terms, Gemini is Google's latest and most powerful AI system that can understand and work with text, code, images, and eventually audio and video, all at the same time. It's designed to be smart, versatile, and integrated into many of the tools we use every day.**\n",
      "Assistant response: I do not have access to your personal information, including your name. I am a large language model, trained by Google.\n"
     ]
    }
   ],
   "source": [
    "response = agent.invoke({\"messages\": []})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "497eca53",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\">{</span>\n",
       "<span style=\"color: #7fbf7f; text-decoration-color: #7fbf7f\">│   </span><span style=\"color: #008000; text-decoration-color: #008000\">'messages'</span>: <span style=\"font-weight: bold\">[</span>\n",
       "<span style=\"color: #7fbf7f; text-decoration-color: #7fbf7f\">│   │   </span><span style=\"color: #800080; text-decoration-color: #800080; font-weight: bold\">SystemMessage</span><span style=\"font-weight: bold\">(</span>\n",
       "<span style=\"color: #7fbf7f; text-decoration-color: #7fbf7f\">│   │   │   </span><span style=\"color: #808000; text-decoration-color: #808000\">content</span>=<span style=\"color: #008000; text-decoration-color: #008000\">'Your are an helpful chatbot with strong memory and recall capabilities.'</span>,\n",
       "<span style=\"color: #7fbf7f; text-decoration-color: #7fbf7f\">│   │   │   </span><span style=\"color: #808000; text-decoration-color: #808000\">additional_kwargs</span>=<span style=\"font-weight: bold\">{}</span>,\n",
       "<span style=\"color: #7fbf7f; text-decoration-color: #7fbf7f\">│   │   │   </span><span style=\"color: #808000; text-decoration-color: #808000\">response_metadata</span>=<span style=\"font-weight: bold\">{}</span>\n",
       "<span style=\"color: #7fbf7f; text-decoration-color: #7fbf7f\">│   │   </span><span style=\"font-weight: bold\">)</span>,\n",
       "<span style=\"color: #7fbf7f; text-decoration-color: #7fbf7f\">│   │   </span><span style=\"color: #800080; text-decoration-color: #800080; font-weight: bold\">HumanMessage</span><span style=\"font-weight: bold\">(</span><span style=\"color: #808000; text-decoration-color: #808000\">content</span>=<span style=\"color: #008000; text-decoration-color: #008000\">'Hi my name is Raunak'</span>, <span style=\"color: #808000; text-decoration-color: #808000\">additional_kwargs</span>=<span style=\"font-weight: bold\">{}</span>, <span style=\"color: #808000; text-decoration-color: #808000\">response_metadata</span>=<span style=\"font-weight: bold\">{})</span>,\n",
       "<span style=\"color: #7fbf7f; text-decoration-color: #7fbf7f\">│   │   </span><span style=\"color: #800080; text-decoration-color: #800080; font-weight: bold\">AIMessage</span><span style=\"font-weight: bold\">(</span>\n",
       "<span style=\"color: #7fbf7f; text-decoration-color: #7fbf7f\">│   │   │   </span><span style=\"color: #808000; text-decoration-color: #808000\">content</span>=<span style=\"color: #008000; text-decoration-color: #008000\">\"Hi Raunak! It's nice to meet you. How can I help you today?\"</span>,\n",
       "<span style=\"color: #7fbf7f; text-decoration-color: #7fbf7f\">│   │   │   </span><span style=\"color: #808000; text-decoration-color: #808000\">additional_kwargs</span>=<span style=\"font-weight: bold\">{</span><span style=\"color: #008000; text-decoration-color: #008000\">'refusal'</span>: <span style=\"color: #800080; text-decoration-color: #800080; font-style: italic\">None</span><span style=\"font-weight: bold\">}</span>,\n",
       "<span style=\"color: #7fbf7f; text-decoration-color: #7fbf7f\">│   │   │   </span><span style=\"color: #808000; text-decoration-color: #808000\">response_metadata</span>=<span style=\"font-weight: bold\">{</span>\n",
       "<span style=\"color: #7fbf7f; text-decoration-color: #7fbf7f\">│   │   │   │   </span><span style=\"color: #008000; text-decoration-color: #008000\">'token_usage'</span>: <span style=\"font-weight: bold\">{</span>\n",
       "<span style=\"color: #7fbf7f; text-decoration-color: #7fbf7f\">│   │   │   │   │   </span><span style=\"color: #008000; text-decoration-color: #008000\">'completion_tokens'</span>: <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">19</span>,\n",
       "<span style=\"color: #7fbf7f; text-decoration-color: #7fbf7f\">│   │   │   │   │   </span><span style=\"color: #008000; text-decoration-color: #008000\">'prompt_tokens'</span>: <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">7</span>,\n",
       "<span style=\"color: #7fbf7f; text-decoration-color: #7fbf7f\">│   │   │   │   │   </span><span style=\"color: #008000; text-decoration-color: #008000\">'total_tokens'</span>: <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">26</span>,\n",
       "<span style=\"color: #7fbf7f; text-decoration-color: #7fbf7f\">│   │   │   │   │   </span><span style=\"color: #008000; text-decoration-color: #008000\">'completion_tokens_details'</span>: <span style=\"color: #800080; text-decoration-color: #800080; font-style: italic\">None</span>,\n",
       "<span style=\"color: #7fbf7f; text-decoration-color: #7fbf7f\">│   │   │   │   │   </span><span style=\"color: #008000; text-decoration-color: #008000\">'prompt_tokens_details'</span>: <span style=\"color: #800080; text-decoration-color: #800080; font-style: italic\">None</span>\n",
       "<span style=\"color: #7fbf7f; text-decoration-color: #7fbf7f\">│   │   │   │   </span><span style=\"font-weight: bold\">}</span>,\n",
       "<span style=\"color: #7fbf7f; text-decoration-color: #7fbf7f\">│   │   │   │   </span><span style=\"color: #008000; text-decoration-color: #008000\">'model_name'</span>: <span style=\"color: #008000; text-decoration-color: #008000\">'gemini-2.5-flash-lite'</span>,\n",
       "<span style=\"color: #7fbf7f; text-decoration-color: #7fbf7f\">│   │   │   │   </span><span style=\"color: #008000; text-decoration-color: #008000\">'system_fingerprint'</span>: <span style=\"color: #800080; text-decoration-color: #800080; font-style: italic\">None</span>,\n",
       "<span style=\"color: #7fbf7f; text-decoration-color: #7fbf7f\">│   │   │   │   </span><span style=\"color: #008000; text-decoration-color: #008000\">'id'</span>: <span style=\"color: #008000; text-decoration-color: #008000\">'KAnYaKPKJ7foz7IPw82kqQk'</span>,\n",
       "<span style=\"color: #7fbf7f; text-decoration-color: #7fbf7f\">│   │   │   │   </span><span style=\"color: #008000; text-decoration-color: #008000\">'service_tier'</span>: <span style=\"color: #800080; text-decoration-color: #800080; font-style: italic\">None</span>,\n",
       "<span style=\"color: #7fbf7f; text-decoration-color: #7fbf7f\">│   │   │   │   </span><span style=\"color: #008000; text-decoration-color: #008000\">'finish_reason'</span>: <span style=\"color: #008000; text-decoration-color: #008000\">'stop'</span>,\n",
       "<span style=\"color: #7fbf7f; text-decoration-color: #7fbf7f\">│   │   │   │   </span><span style=\"color: #008000; text-decoration-color: #008000\">'logprobs'</span>: <span style=\"color: #800080; text-decoration-color: #800080; font-style: italic\">None</span>\n",
       "<span style=\"color: #7fbf7f; text-decoration-color: #7fbf7f\">│   │   │   </span><span style=\"font-weight: bold\">}</span>,\n",
       "<span style=\"color: #7fbf7f; text-decoration-color: #7fbf7f\">│   │   │   </span><span style=\"color: #808000; text-decoration-color: #808000\">id</span>=<span style=\"color: #008000; text-decoration-color: #008000\">'run--47e1caec-6192-4193-961d-d620a509333b-0'</span>,\n",
       "<span style=\"color: #7fbf7f; text-decoration-color: #7fbf7f\">│   │   │   </span><span style=\"color: #808000; text-decoration-color: #808000\">usage_metadata</span>=<span style=\"font-weight: bold\">{</span>\n",
       "<span style=\"color: #7fbf7f; text-decoration-color: #7fbf7f\">│   │   │   │   </span><span style=\"color: #008000; text-decoration-color: #008000\">'input_tokens'</span>: <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">7</span>,\n",
       "<span style=\"color: #7fbf7f; text-decoration-color: #7fbf7f\">│   │   │   │   </span><span style=\"color: #008000; text-decoration-color: #008000\">'output_tokens'</span>: <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">19</span>,\n",
       "<span style=\"color: #7fbf7f; text-decoration-color: #7fbf7f\">│   │   │   │   </span><span style=\"color: #008000; text-decoration-color: #008000\">'total_tokens'</span>: <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">26</span>,\n",
       "<span style=\"color: #7fbf7f; text-decoration-color: #7fbf7f\">│   │   │   │   </span><span style=\"color: #008000; text-decoration-color: #008000\">'input_token_details'</span>: <span style=\"font-weight: bold\">{}</span>,\n",
       "<span style=\"color: #7fbf7f; text-decoration-color: #7fbf7f\">│   │   │   │   </span><span style=\"color: #008000; text-decoration-color: #008000\">'output_token_details'</span>: <span style=\"font-weight: bold\">{}</span>\n",
       "<span style=\"color: #7fbf7f; text-decoration-color: #7fbf7f\">│   │   │   </span><span style=\"font-weight: bold\">}</span>\n",
       "<span style=\"color: #7fbf7f; text-decoration-color: #7fbf7f\">│   │   </span><span style=\"font-weight: bold\">)</span>,\n",
       "<span style=\"color: #7fbf7f; text-decoration-color: #7fbf7f\">│   │   </span><span style=\"color: #800080; text-decoration-color: #800080; font-weight: bold\">HumanMessage</span><span style=\"font-weight: bold\">(</span><span style=\"color: #808000; text-decoration-color: #808000\">content</span>=<span style=\"color: #008000; text-decoration-color: #008000\">'What is Gemini?'</span>, <span style=\"color: #808000; text-decoration-color: #808000\">additional_kwargs</span>=<span style=\"font-weight: bold\">{}</span>, <span style=\"color: #808000; text-decoration-color: #808000\">response_metadata</span>=<span style=\"font-weight: bold\">{})</span>,\n",
       "<span style=\"color: #7fbf7f; text-decoration-color: #7fbf7f\">│   │   </span><span style=\"color: #800080; text-decoration-color: #800080; font-weight: bold\">AIMessage</span><span style=\"font-weight: bold\">(</span>\n",
       "<span style=\"color: #7fbf7f; text-decoration-color: #7fbf7f\">│   │   │   </span><span style=\"color: #808000; text-decoration-color: #808000\">content</span>=<span style=\"color: #008000; text-decoration-color: #008000\">\"Gemini is a **family of large language models (LLMs)** developed by **Google AI**. Think of it as a highly advanced AI system designed to understand and generate human-like text, and increasingly, to process and reason about other types of information like code, images, audio, and video.\\n\\nHere's a breakdown of what that means and what makes Gemini significant:\\n\\n**Key Characteristics of Gemini:**\\n\\n*   **Multimodal:** This is a core differentiator. Gemini is designed from the ground up to be multimodal, meaning it can understand and operate across different types of information simultaneously. This allows it to:\\n    *   **Understand text and code:** Like many LLMs, it can write, translate, answer questions, and summarize text. It's also proficient in various programming languages.\\n    *   **Process images:** It can analyze images, describe their content, answer questions about them, and even generate captions.\\n    *   **Understand audio and video:** While still evolving, Gemini is being developed to process and reason about audio and video content, opening up possibilities for more complex interactions.\\n\\n*   **Designed for Scale and Efficiency:** Gemini comes in different sizes, optimized for various tasks and devices:\\n    *   **Gemini Ultra:** The largest and most capable model, designed for highly complex tasks.\\n    *   **Gemini Pro:** A versatile model that balances capability with efficiency, suitable for a wide range of applications.\\n    *   **Gemini Nano:** The most efficient model, designed to run directly on mobile devices, enabling on-device AI experiences.\\n\\n*   **Advanced Reasoning Capabilities:** Gemini aims to go beyond simple pattern matching. It's designed to:\\n    *   **Reason logically:** It can follow complex instructions and perform multi-step reasoning.\\n    *   **Understand context:** It can grasp the nuances of conversations and information.\\n    *   **Solve problems:** It can be applied to a variety of problem-solving scenarios.\\n\\n*   **Built for Integration:** Gemini is intended to be integrated into a wide range of Google products and services, as well as made available to developers through APIs. This means you'll likely encounter Gemini powering features in:\\n    *   **Google Search:** Enhancing search results and providing more conversational answers.\\n    *   **Google Workspace:** Assisting with writing, summarizing, and analyzing documents, emails, and spreadsheets.\\n    *   **Google Cloud:** Providing AI capabilities for businesses and developers.\\n    *   **Android devices:** Enabling new on-device AI features.\\n\\n**Why is Gemini Important?**\\n\\nGemini represents a significant step forward in AI development for several reasons:\\n\\n*   **True Multimodality:** Its native multimodal design is a key advancement, allowing for more holistic understanding and interaction with the world.\\n*   **Performance:** Google claims Gemini Ultra outperforms existing state-of-the-art models on many benchmarks, particularly in multimodal reasoning.\\n*   **Accessibility:** The different model sizes make advanced AI accessible across a spectrum of devices and applications.\\n*   **Future of AI:** It's positioned as a foundational technology for future AI advancements and applications.\\n\\n**In simpler terms, Gemini is Google's latest and most powerful AI system that can understand and work with text, code, images, and eventually audio and video, all at the same time. It's designed to be smart, versatile, and integrated into many of the tools we use every day.**\"</span>,\n",
       "<span style=\"color: #7fbf7f; text-decoration-color: #7fbf7f\">│   │   │   </span><span style=\"color: #808000; text-decoration-color: #808000\">additional_kwargs</span>=<span style=\"font-weight: bold\">{</span><span style=\"color: #008000; text-decoration-color: #008000\">'refusal'</span>: <span style=\"color: #800080; text-decoration-color: #800080; font-style: italic\">None</span><span style=\"font-weight: bold\">}</span>,\n",
       "<span style=\"color: #7fbf7f; text-decoration-color: #7fbf7f\">│   │   │   </span><span style=\"color: #808000; text-decoration-color: #808000\">response_metadata</span>=<span style=\"font-weight: bold\">{</span>\n",
       "<span style=\"color: #7fbf7f; text-decoration-color: #7fbf7f\">│   │   │   │   </span><span style=\"color: #008000; text-decoration-color: #008000\">'token_usage'</span>: <span style=\"font-weight: bold\">{</span>\n",
       "<span style=\"color: #7fbf7f; text-decoration-color: #7fbf7f\">│   │   │   │   │   </span><span style=\"color: #008000; text-decoration-color: #008000\">'completion_tokens'</span>: <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">718</span>,\n",
       "<span style=\"color: #7fbf7f; text-decoration-color: #7fbf7f\">│   │   │   │   │   </span><span style=\"color: #008000; text-decoration-color: #008000\">'prompt_tokens'</span>: <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">5</span>,\n",
       "<span style=\"color: #7fbf7f; text-decoration-color: #7fbf7f\">│   │   │   │   │   </span><span style=\"color: #008000; text-decoration-color: #008000\">'total_tokens'</span>: <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">723</span>,\n",
       "<span style=\"color: #7fbf7f; text-decoration-color: #7fbf7f\">│   │   │   │   │   </span><span style=\"color: #008000; text-decoration-color: #008000\">'completion_tokens_details'</span>: <span style=\"color: #800080; text-decoration-color: #800080; font-style: italic\">None</span>,\n",
       "<span style=\"color: #7fbf7f; text-decoration-color: #7fbf7f\">│   │   │   │   │   </span><span style=\"color: #008000; text-decoration-color: #008000\">'prompt_tokens_details'</span>: <span style=\"color: #800080; text-decoration-color: #800080; font-style: italic\">None</span>\n",
       "<span style=\"color: #7fbf7f; text-decoration-color: #7fbf7f\">│   │   │   │   </span><span style=\"font-weight: bold\">}</span>,\n",
       "<span style=\"color: #7fbf7f; text-decoration-color: #7fbf7f\">│   │   │   │   </span><span style=\"color: #008000; text-decoration-color: #008000\">'model_name'</span>: <span style=\"color: #008000; text-decoration-color: #008000\">'gemini-2.5-flash-lite'</span>,\n",
       "<span style=\"color: #7fbf7f; text-decoration-color: #7fbf7f\">│   │   │   │   </span><span style=\"color: #008000; text-decoration-color: #008000\">'system_fingerprint'</span>: <span style=\"color: #800080; text-decoration-color: #800080; font-style: italic\">None</span>,\n",
       "<span style=\"color: #7fbf7f; text-decoration-color: #7fbf7f\">│   │   │   │   </span><span style=\"color: #008000; text-decoration-color: #008000\">'id'</span>: <span style=\"color: #008000; text-decoration-color: #008000\">'NwnYaMO2F6qBmtkPoaPR4Qo'</span>,\n",
       "<span style=\"color: #7fbf7f; text-decoration-color: #7fbf7f\">│   │   │   │   </span><span style=\"color: #008000; text-decoration-color: #008000\">'service_tier'</span>: <span style=\"color: #800080; text-decoration-color: #800080; font-style: italic\">None</span>,\n",
       "<span style=\"color: #7fbf7f; text-decoration-color: #7fbf7f\">│   │   │   │   </span><span style=\"color: #008000; text-decoration-color: #008000\">'finish_reason'</span>: <span style=\"color: #008000; text-decoration-color: #008000\">'stop'</span>,\n",
       "<span style=\"color: #7fbf7f; text-decoration-color: #7fbf7f\">│   │   │   │   </span><span style=\"color: #008000; text-decoration-color: #008000\">'logprobs'</span>: <span style=\"color: #800080; text-decoration-color: #800080; font-style: italic\">None</span>\n",
       "<span style=\"color: #7fbf7f; text-decoration-color: #7fbf7f\">│   │   │   </span><span style=\"font-weight: bold\">}</span>,\n",
       "<span style=\"color: #7fbf7f; text-decoration-color: #7fbf7f\">│   │   │   </span><span style=\"color: #808000; text-decoration-color: #808000\">id</span>=<span style=\"color: #008000; text-decoration-color: #008000\">'run--026e9da5-a1d9-4fee-b82b-4fcf84ded6b2-0'</span>,\n",
       "<span style=\"color: #7fbf7f; text-decoration-color: #7fbf7f\">│   │   │   </span><span style=\"color: #808000; text-decoration-color: #808000\">usage_metadata</span>=<span style=\"font-weight: bold\">{</span>\n",
       "<span style=\"color: #7fbf7f; text-decoration-color: #7fbf7f\">│   │   │   │   </span><span style=\"color: #008000; text-decoration-color: #008000\">'input_tokens'</span>: <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">5</span>,\n",
       "<span style=\"color: #7fbf7f; text-decoration-color: #7fbf7f\">│   │   │   │   </span><span style=\"color: #008000; text-decoration-color: #008000\">'output_tokens'</span>: <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">718</span>,\n",
       "<span style=\"color: #7fbf7f; text-decoration-color: #7fbf7f\">│   │   │   │   </span><span style=\"color: #008000; text-decoration-color: #008000\">'total_tokens'</span>: <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">723</span>,\n",
       "<span style=\"color: #7fbf7f; text-decoration-color: #7fbf7f\">│   │   │   │   </span><span style=\"color: #008000; text-decoration-color: #008000\">'input_token_details'</span>: <span style=\"font-weight: bold\">{}</span>,\n",
       "<span style=\"color: #7fbf7f; text-decoration-color: #7fbf7f\">│   │   │   │   </span><span style=\"color: #008000; text-decoration-color: #008000\">'output_token_details'</span>: <span style=\"font-weight: bold\">{}</span>\n",
       "<span style=\"color: #7fbf7f; text-decoration-color: #7fbf7f\">│   │   │   </span><span style=\"font-weight: bold\">}</span>\n",
       "<span style=\"color: #7fbf7f; text-decoration-color: #7fbf7f\">│   │   </span><span style=\"font-weight: bold\">)</span>,\n",
       "<span style=\"color: #7fbf7f; text-decoration-color: #7fbf7f\">│   │   </span><span style=\"color: #800080; text-decoration-color: #800080; font-weight: bold\">HumanMessage</span><span style=\"font-weight: bold\">(</span><span style=\"color: #808000; text-decoration-color: #808000\">content</span>=<span style=\"color: #008000; text-decoration-color: #008000\">\"WHat's my name?\"</span>, <span style=\"color: #808000; text-decoration-color: #808000\">additional_kwargs</span>=<span style=\"font-weight: bold\">{}</span>, <span style=\"color: #808000; text-decoration-color: #808000\">response_metadata</span>=<span style=\"font-weight: bold\">{})</span>,\n",
       "<span style=\"color: #7fbf7f; text-decoration-color: #7fbf7f\">│   │   </span><span style=\"color: #800080; text-decoration-color: #800080; font-weight: bold\">AIMessage</span><span style=\"font-weight: bold\">(</span>\n",
       "<span style=\"color: #7fbf7f; text-decoration-color: #7fbf7f\">│   │   │   </span><span style=\"color: #808000; text-decoration-color: #808000\">content</span>=<span style=\"color: #008000; text-decoration-color: #008000\">'I do not have access to your personal information, including your name. I am a large language model, trained by Google.'</span>,\n",
       "<span style=\"color: #7fbf7f; text-decoration-color: #7fbf7f\">│   │   │   </span><span style=\"color: #808000; text-decoration-color: #808000\">additional_kwargs</span>=<span style=\"font-weight: bold\">{</span><span style=\"color: #008000; text-decoration-color: #008000\">'refusal'</span>: <span style=\"color: #800080; text-decoration-color: #800080; font-style: italic\">None</span><span style=\"font-weight: bold\">}</span>,\n",
       "<span style=\"color: #7fbf7f; text-decoration-color: #7fbf7f\">│   │   │   </span><span style=\"color: #808000; text-decoration-color: #808000\">response_metadata</span>=<span style=\"font-weight: bold\">{</span>\n",
       "<span style=\"color: #7fbf7f; text-decoration-color: #7fbf7f\">│   │   │   │   </span><span style=\"color: #008000; text-decoration-color: #008000\">'token_usage'</span>: <span style=\"font-weight: bold\">{</span>\n",
       "<span style=\"color: #7fbf7f; text-decoration-color: #7fbf7f\">│   │   │   │   │   </span><span style=\"color: #008000; text-decoration-color: #008000\">'completion_tokens'</span>: <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">25</span>,\n",
       "<span style=\"color: #7fbf7f; text-decoration-color: #7fbf7f\">│   │   │   │   │   </span><span style=\"color: #008000; text-decoration-color: #008000\">'prompt_tokens'</span>: <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">8</span>,\n",
       "<span style=\"color: #7fbf7f; text-decoration-color: #7fbf7f\">│   │   │   │   │   </span><span style=\"color: #008000; text-decoration-color: #008000\">'total_tokens'</span>: <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">33</span>,\n",
       "<span style=\"color: #7fbf7f; text-decoration-color: #7fbf7f\">│   │   │   │   │   </span><span style=\"color: #008000; text-decoration-color: #008000\">'completion_tokens_details'</span>: <span style=\"color: #800080; text-decoration-color: #800080; font-style: italic\">None</span>,\n",
       "<span style=\"color: #7fbf7f; text-decoration-color: #7fbf7f\">│   │   │   │   │   </span><span style=\"color: #008000; text-decoration-color: #008000\">'prompt_tokens_details'</span>: <span style=\"color: #800080; text-decoration-color: #800080; font-style: italic\">None</span>\n",
       "<span style=\"color: #7fbf7f; text-decoration-color: #7fbf7f\">│   │   │   │   </span><span style=\"font-weight: bold\">}</span>,\n",
       "<span style=\"color: #7fbf7f; text-decoration-color: #7fbf7f\">│   │   │   │   </span><span style=\"color: #008000; text-decoration-color: #008000\">'model_name'</span>: <span style=\"color: #008000; text-decoration-color: #008000\">'gemini-2.5-flash-lite'</span>,\n",
       "<span style=\"color: #7fbf7f; text-decoration-color: #7fbf7f\">│   │   │   │   </span><span style=\"color: #008000; text-decoration-color: #008000\">'system_fingerprint'</span>: <span style=\"color: #800080; text-decoration-color: #800080; font-style: italic\">None</span>,\n",
       "<span style=\"color: #7fbf7f; text-decoration-color: #7fbf7f\">│   │   │   │   </span><span style=\"color: #008000; text-decoration-color: #008000\">'id'</span>: <span style=\"color: #008000; text-decoration-color: #008000\">'QwnYaKLMA9eY0-kP2L2SmAk'</span>,\n",
       "<span style=\"color: #7fbf7f; text-decoration-color: #7fbf7f\">│   │   │   │   </span><span style=\"color: #008000; text-decoration-color: #008000\">'service_tier'</span>: <span style=\"color: #800080; text-decoration-color: #800080; font-style: italic\">None</span>,\n",
       "<span style=\"color: #7fbf7f; text-decoration-color: #7fbf7f\">│   │   │   │   </span><span style=\"color: #008000; text-decoration-color: #008000\">'finish_reason'</span>: <span style=\"color: #008000; text-decoration-color: #008000\">'stop'</span>,\n",
       "<span style=\"color: #7fbf7f; text-decoration-color: #7fbf7f\">│   │   │   │   </span><span style=\"color: #008000; text-decoration-color: #008000\">'logprobs'</span>: <span style=\"color: #800080; text-decoration-color: #800080; font-style: italic\">None</span>\n",
       "<span style=\"color: #7fbf7f; text-decoration-color: #7fbf7f\">│   │   │   </span><span style=\"font-weight: bold\">}</span>,\n",
       "<span style=\"color: #7fbf7f; text-decoration-color: #7fbf7f\">│   │   │   </span><span style=\"color: #808000; text-decoration-color: #808000\">id</span>=<span style=\"color: #008000; text-decoration-color: #008000\">'run--1f56c980-b707-4958-bf18-fe34eaf7dc19-0'</span>,\n",
       "<span style=\"color: #7fbf7f; text-decoration-color: #7fbf7f\">│   │   │   </span><span style=\"color: #808000; text-decoration-color: #808000\">usage_metadata</span>=<span style=\"font-weight: bold\">{</span>\n",
       "<span style=\"color: #7fbf7f; text-decoration-color: #7fbf7f\">│   │   │   │   </span><span style=\"color: #008000; text-decoration-color: #008000\">'input_tokens'</span>: <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">8</span>,\n",
       "<span style=\"color: #7fbf7f; text-decoration-color: #7fbf7f\">│   │   │   │   </span><span style=\"color: #008000; text-decoration-color: #008000\">'output_tokens'</span>: <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">25</span>,\n",
       "<span style=\"color: #7fbf7f; text-decoration-color: #7fbf7f\">│   │   │   │   </span><span style=\"color: #008000; text-decoration-color: #008000\">'total_tokens'</span>: <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">33</span>,\n",
       "<span style=\"color: #7fbf7f; text-decoration-color: #7fbf7f\">│   │   │   │   </span><span style=\"color: #008000; text-decoration-color: #008000\">'input_token_details'</span>: <span style=\"font-weight: bold\">{}</span>,\n",
       "<span style=\"color: #7fbf7f; text-decoration-color: #7fbf7f\">│   │   │   │   </span><span style=\"color: #008000; text-decoration-color: #008000\">'output_token_details'</span>: <span style=\"font-weight: bold\">{}</span>\n",
       "<span style=\"color: #7fbf7f; text-decoration-color: #7fbf7f\">│   │   │   </span><span style=\"font-weight: bold\">}</span>\n",
       "<span style=\"color: #7fbf7f; text-decoration-color: #7fbf7f\">│   │   </span><span style=\"font-weight: bold\">)</span>\n",
       "<span style=\"color: #7fbf7f; text-decoration-color: #7fbf7f\">│   </span><span style=\"font-weight: bold\">]</span>\n",
       "<span style=\"font-weight: bold\">}</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m{\u001b[0m\n",
       "\u001b[2;32m│   \u001b[0m\u001b[32m'messages'\u001b[0m: \u001b[1m[\u001b[0m\n",
       "\u001b[2;32m│   │   \u001b[0m\u001b[1;35mSystemMessage\u001b[0m\u001b[1m(\u001b[0m\n",
       "\u001b[2;32m│   │   │   \u001b[0m\u001b[33mcontent\u001b[0m=\u001b[32m'Your are an helpful chatbot with strong memory and recall capabilities.'\u001b[0m,\n",
       "\u001b[2;32m│   │   │   \u001b[0m\u001b[33madditional_kwargs\u001b[0m=\u001b[1m{\u001b[0m\u001b[1m}\u001b[0m,\n",
       "\u001b[2;32m│   │   │   \u001b[0m\u001b[33mresponse_metadata\u001b[0m=\u001b[1m{\u001b[0m\u001b[1m}\u001b[0m\n",
       "\u001b[2;32m│   │   \u001b[0m\u001b[1m)\u001b[0m,\n",
       "\u001b[2;32m│   │   \u001b[0m\u001b[1;35mHumanMessage\u001b[0m\u001b[1m(\u001b[0m\u001b[33mcontent\u001b[0m=\u001b[32m'Hi my name is Raunak'\u001b[0m, \u001b[33madditional_kwargs\u001b[0m=\u001b[1m{\u001b[0m\u001b[1m}\u001b[0m, \u001b[33mresponse_metadata\u001b[0m=\u001b[1m{\u001b[0m\u001b[1m}\u001b[0m\u001b[1m)\u001b[0m,\n",
       "\u001b[2;32m│   │   \u001b[0m\u001b[1;35mAIMessage\u001b[0m\u001b[1m(\u001b[0m\n",
       "\u001b[2;32m│   │   │   \u001b[0m\u001b[33mcontent\u001b[0m=\u001b[32m\"Hi\u001b[0m\u001b[32m Raunak! It's nice to meet you. How can I help you today?\"\u001b[0m,\n",
       "\u001b[2;32m│   │   │   \u001b[0m\u001b[33madditional_kwargs\u001b[0m=\u001b[1m{\u001b[0m\u001b[32m'refusal'\u001b[0m: \u001b[3;35mNone\u001b[0m\u001b[1m}\u001b[0m,\n",
       "\u001b[2;32m│   │   │   \u001b[0m\u001b[33mresponse_metadata\u001b[0m=\u001b[1m{\u001b[0m\n",
       "\u001b[2;32m│   │   │   │   \u001b[0m\u001b[32m'token_usage'\u001b[0m: \u001b[1m{\u001b[0m\n",
       "\u001b[2;32m│   │   │   │   │   \u001b[0m\u001b[32m'completion_tokens'\u001b[0m: \u001b[1;36m19\u001b[0m,\n",
       "\u001b[2;32m│   │   │   │   │   \u001b[0m\u001b[32m'prompt_tokens'\u001b[0m: \u001b[1;36m7\u001b[0m,\n",
       "\u001b[2;32m│   │   │   │   │   \u001b[0m\u001b[32m'total_tokens'\u001b[0m: \u001b[1;36m26\u001b[0m,\n",
       "\u001b[2;32m│   │   │   │   │   \u001b[0m\u001b[32m'completion_tokens_details'\u001b[0m: \u001b[3;35mNone\u001b[0m,\n",
       "\u001b[2;32m│   │   │   │   │   \u001b[0m\u001b[32m'prompt_tokens_details'\u001b[0m: \u001b[3;35mNone\u001b[0m\n",
       "\u001b[2;32m│   │   │   │   \u001b[0m\u001b[1m}\u001b[0m,\n",
       "\u001b[2;32m│   │   │   │   \u001b[0m\u001b[32m'model_name'\u001b[0m: \u001b[32m'gemini-2.5-flash-lite'\u001b[0m,\n",
       "\u001b[2;32m│   │   │   │   \u001b[0m\u001b[32m'system_fingerprint'\u001b[0m: \u001b[3;35mNone\u001b[0m,\n",
       "\u001b[2;32m│   │   │   │   \u001b[0m\u001b[32m'id'\u001b[0m: \u001b[32m'KAnYaKPKJ7foz7IPw82kqQk'\u001b[0m,\n",
       "\u001b[2;32m│   │   │   │   \u001b[0m\u001b[32m'service_tier'\u001b[0m: \u001b[3;35mNone\u001b[0m,\n",
       "\u001b[2;32m│   │   │   │   \u001b[0m\u001b[32m'finish_reason'\u001b[0m: \u001b[32m'stop'\u001b[0m,\n",
       "\u001b[2;32m│   │   │   │   \u001b[0m\u001b[32m'logprobs'\u001b[0m: \u001b[3;35mNone\u001b[0m\n",
       "\u001b[2;32m│   │   │   \u001b[0m\u001b[1m}\u001b[0m,\n",
       "\u001b[2;32m│   │   │   \u001b[0m\u001b[33mid\u001b[0m=\u001b[32m'run--47e1caec-6192-4193-961d-d620a509333b-0'\u001b[0m,\n",
       "\u001b[2;32m│   │   │   \u001b[0m\u001b[33musage_metadata\u001b[0m=\u001b[1m{\u001b[0m\n",
       "\u001b[2;32m│   │   │   │   \u001b[0m\u001b[32m'input_tokens'\u001b[0m: \u001b[1;36m7\u001b[0m,\n",
       "\u001b[2;32m│   │   │   │   \u001b[0m\u001b[32m'output_tokens'\u001b[0m: \u001b[1;36m19\u001b[0m,\n",
       "\u001b[2;32m│   │   │   │   \u001b[0m\u001b[32m'total_tokens'\u001b[0m: \u001b[1;36m26\u001b[0m,\n",
       "\u001b[2;32m│   │   │   │   \u001b[0m\u001b[32m'input_token_details'\u001b[0m: \u001b[1m{\u001b[0m\u001b[1m}\u001b[0m,\n",
       "\u001b[2;32m│   │   │   │   \u001b[0m\u001b[32m'output_token_details'\u001b[0m: \u001b[1m{\u001b[0m\u001b[1m}\u001b[0m\n",
       "\u001b[2;32m│   │   │   \u001b[0m\u001b[1m}\u001b[0m\n",
       "\u001b[2;32m│   │   \u001b[0m\u001b[1m)\u001b[0m,\n",
       "\u001b[2;32m│   │   \u001b[0m\u001b[1;35mHumanMessage\u001b[0m\u001b[1m(\u001b[0m\u001b[33mcontent\u001b[0m=\u001b[32m'What is Gemini?'\u001b[0m, \u001b[33madditional_kwargs\u001b[0m=\u001b[1m{\u001b[0m\u001b[1m}\u001b[0m, \u001b[33mresponse_metadata\u001b[0m=\u001b[1m{\u001b[0m\u001b[1m}\u001b[0m\u001b[1m)\u001b[0m,\n",
       "\u001b[2;32m│   │   \u001b[0m\u001b[1;35mAIMessage\u001b[0m\u001b[1m(\u001b[0m\n",
       "\u001b[2;32m│   │   │   \u001b[0m\u001b[33mcontent\u001b[0m=\u001b[32m\"Gemini\u001b[0m\u001b[32m is a **family of large language models \u001b[0m\u001b[32m(\u001b[0m\u001b[32mLLMs\u001b[0m\u001b[32m)\u001b[0m\u001b[32m** developed by **Google AI**. Think of it as a highly advanced AI system designed to understand and generate human-like text, and increasingly, to process and reason about other types of information like code, images, audio, and video.\\n\\nHere's a breakdown of what that means and what makes Gemini significant:\\n\\n**Key Characteristics of Gemini:**\\n\\n*   **Multimodal:** This is a core differentiator. Gemini is designed from the ground up to be multimodal, meaning it can understand and operate across different types of information simultaneously. This allows it to:\\n    *   **Understand text and code:** Like many LLMs, it can write, translate, answer questions, and summarize text. It's also proficient in various programming languages.\\n    *   **Process images:** It can analyze images, describe their content, answer questions about them, and even generate captions.\\n    *   **Understand audio and video:** While still evolving, Gemini is being developed to process and reason about audio and video content, opening up possibilities for more complex interactions.\\n\\n*   **Designed for Scale and Efficiency:** Gemini comes in different sizes, optimized for various tasks and devices:\\n    *   **Gemini Ultra:** The largest and most capable model, designed for highly complex tasks.\\n    *   **Gemini Pro:** A versatile model that balances capability with efficiency, suitable for a wide range of applications.\\n    *   **Gemini Nano:** The most efficient model, designed to run directly on mobile devices, enabling on-device AI experiences.\\n\\n*   **Advanced Reasoning Capabilities:** Gemini aims to go beyond simple pattern matching. It's designed to:\\n    *   **Reason logically:** It can follow complex instructions and perform multi-step reasoning.\\n    *   **Understand context:** It can grasp the nuances of conversations and information.\\n    *   **Solve problems:** It can be applied to a variety of problem-solving scenarios.\\n\\n*   **Built for Integration:** Gemini is intended to be integrated into a wide range of Google products and services, as well as made available to developers through APIs. This means you'll likely encounter Gemini powering features in:\\n    *   **Google Search:** Enhancing search results and providing more conversational answers.\\n    *   **Google Workspace:** Assisting with writing, summarizing, and analyzing documents, emails, and spreadsheets.\\n    *   **Google Cloud:** Providing AI capabilities for businesses and developers.\\n    *   **Android devices:** Enabling new on-device AI features.\\n\\n**Why is Gemini Important?**\\n\\nGemini represents a significant step forward in AI development for several reasons:\\n\\n*   **True Multimodality:** Its native multimodal design is a key advancement, allowing for more holistic understanding and interaction with the world.\\n*   **Performance:** Google claims Gemini Ultra outperforms existing state-of-the-art models on many benchmarks, particularly in multimodal reasoning.\\n*   **Accessibility:** The different model sizes make advanced AI accessible across a spectrum of devices and applications.\\n*   **Future of AI:** It's positioned as a foundational technology for future AI advancements and applications.\\n\\n**In simpler terms, Gemini is Google's latest and most powerful AI system that can understand and work with text, code, images, and eventually audio and video, all at the same time. It's designed to be smart, versatile, and integrated into many of the tools we use every day.**\"\u001b[0m,\n",
       "\u001b[2;32m│   │   │   \u001b[0m\u001b[33madditional_kwargs\u001b[0m=\u001b[1m{\u001b[0m\u001b[32m'refusal'\u001b[0m: \u001b[3;35mNone\u001b[0m\u001b[1m}\u001b[0m,\n",
       "\u001b[2;32m│   │   │   \u001b[0m\u001b[33mresponse_metadata\u001b[0m=\u001b[1m{\u001b[0m\n",
       "\u001b[2;32m│   │   │   │   \u001b[0m\u001b[32m'token_usage'\u001b[0m: \u001b[1m{\u001b[0m\n",
       "\u001b[2;32m│   │   │   │   │   \u001b[0m\u001b[32m'completion_tokens'\u001b[0m: \u001b[1;36m718\u001b[0m,\n",
       "\u001b[2;32m│   │   │   │   │   \u001b[0m\u001b[32m'prompt_tokens'\u001b[0m: \u001b[1;36m5\u001b[0m,\n",
       "\u001b[2;32m│   │   │   │   │   \u001b[0m\u001b[32m'total_tokens'\u001b[0m: \u001b[1;36m723\u001b[0m,\n",
       "\u001b[2;32m│   │   │   │   │   \u001b[0m\u001b[32m'completion_tokens_details'\u001b[0m: \u001b[3;35mNone\u001b[0m,\n",
       "\u001b[2;32m│   │   │   │   │   \u001b[0m\u001b[32m'prompt_tokens_details'\u001b[0m: \u001b[3;35mNone\u001b[0m\n",
       "\u001b[2;32m│   │   │   │   \u001b[0m\u001b[1m}\u001b[0m,\n",
       "\u001b[2;32m│   │   │   │   \u001b[0m\u001b[32m'model_name'\u001b[0m: \u001b[32m'gemini-2.5-flash-lite'\u001b[0m,\n",
       "\u001b[2;32m│   │   │   │   \u001b[0m\u001b[32m'system_fingerprint'\u001b[0m: \u001b[3;35mNone\u001b[0m,\n",
       "\u001b[2;32m│   │   │   │   \u001b[0m\u001b[32m'id'\u001b[0m: \u001b[32m'NwnYaMO2F6qBmtkPoaPR4Qo'\u001b[0m,\n",
       "\u001b[2;32m│   │   │   │   \u001b[0m\u001b[32m'service_tier'\u001b[0m: \u001b[3;35mNone\u001b[0m,\n",
       "\u001b[2;32m│   │   │   │   \u001b[0m\u001b[32m'finish_reason'\u001b[0m: \u001b[32m'stop'\u001b[0m,\n",
       "\u001b[2;32m│   │   │   │   \u001b[0m\u001b[32m'logprobs'\u001b[0m: \u001b[3;35mNone\u001b[0m\n",
       "\u001b[2;32m│   │   │   \u001b[0m\u001b[1m}\u001b[0m,\n",
       "\u001b[2;32m│   │   │   \u001b[0m\u001b[33mid\u001b[0m=\u001b[32m'run--026e9da5-a1d9-4fee-b82b-4fcf84ded6b2-0'\u001b[0m,\n",
       "\u001b[2;32m│   │   │   \u001b[0m\u001b[33musage_metadata\u001b[0m=\u001b[1m{\u001b[0m\n",
       "\u001b[2;32m│   │   │   │   \u001b[0m\u001b[32m'input_tokens'\u001b[0m: \u001b[1;36m5\u001b[0m,\n",
       "\u001b[2;32m│   │   │   │   \u001b[0m\u001b[32m'output_tokens'\u001b[0m: \u001b[1;36m718\u001b[0m,\n",
       "\u001b[2;32m│   │   │   │   \u001b[0m\u001b[32m'total_tokens'\u001b[0m: \u001b[1;36m723\u001b[0m,\n",
       "\u001b[2;32m│   │   │   │   \u001b[0m\u001b[32m'input_token_details'\u001b[0m: \u001b[1m{\u001b[0m\u001b[1m}\u001b[0m,\n",
       "\u001b[2;32m│   │   │   │   \u001b[0m\u001b[32m'output_token_details'\u001b[0m: \u001b[1m{\u001b[0m\u001b[1m}\u001b[0m\n",
       "\u001b[2;32m│   │   │   \u001b[0m\u001b[1m}\u001b[0m\n",
       "\u001b[2;32m│   │   \u001b[0m\u001b[1m)\u001b[0m,\n",
       "\u001b[2;32m│   │   \u001b[0m\u001b[1;35mHumanMessage\u001b[0m\u001b[1m(\u001b[0m\u001b[33mcontent\u001b[0m=\u001b[32m\"WHat\u001b[0m\u001b[32m's my name?\"\u001b[0m, \u001b[33madditional_kwargs\u001b[0m=\u001b[1m{\u001b[0m\u001b[1m}\u001b[0m, \u001b[33mresponse_metadata\u001b[0m=\u001b[1m{\u001b[0m\u001b[1m}\u001b[0m\u001b[1m)\u001b[0m,\n",
       "\u001b[2;32m│   │   \u001b[0m\u001b[1;35mAIMessage\u001b[0m\u001b[1m(\u001b[0m\n",
       "\u001b[2;32m│   │   │   \u001b[0m\u001b[33mcontent\u001b[0m=\u001b[32m'I do not have access to your personal information, including your name. I am a large language model, trained by Google.'\u001b[0m,\n",
       "\u001b[2;32m│   │   │   \u001b[0m\u001b[33madditional_kwargs\u001b[0m=\u001b[1m{\u001b[0m\u001b[32m'refusal'\u001b[0m: \u001b[3;35mNone\u001b[0m\u001b[1m}\u001b[0m,\n",
       "\u001b[2;32m│   │   │   \u001b[0m\u001b[33mresponse_metadata\u001b[0m=\u001b[1m{\u001b[0m\n",
       "\u001b[2;32m│   │   │   │   \u001b[0m\u001b[32m'token_usage'\u001b[0m: \u001b[1m{\u001b[0m\n",
       "\u001b[2;32m│   │   │   │   │   \u001b[0m\u001b[32m'completion_tokens'\u001b[0m: \u001b[1;36m25\u001b[0m,\n",
       "\u001b[2;32m│   │   │   │   │   \u001b[0m\u001b[32m'prompt_tokens'\u001b[0m: \u001b[1;36m8\u001b[0m,\n",
       "\u001b[2;32m│   │   │   │   │   \u001b[0m\u001b[32m'total_tokens'\u001b[0m: \u001b[1;36m33\u001b[0m,\n",
       "\u001b[2;32m│   │   │   │   │   \u001b[0m\u001b[32m'completion_tokens_details'\u001b[0m: \u001b[3;35mNone\u001b[0m,\n",
       "\u001b[2;32m│   │   │   │   │   \u001b[0m\u001b[32m'prompt_tokens_details'\u001b[0m: \u001b[3;35mNone\u001b[0m\n",
       "\u001b[2;32m│   │   │   │   \u001b[0m\u001b[1m}\u001b[0m,\n",
       "\u001b[2;32m│   │   │   │   \u001b[0m\u001b[32m'model_name'\u001b[0m: \u001b[32m'gemini-2.5-flash-lite'\u001b[0m,\n",
       "\u001b[2;32m│   │   │   │   \u001b[0m\u001b[32m'system_fingerprint'\u001b[0m: \u001b[3;35mNone\u001b[0m,\n",
       "\u001b[2;32m│   │   │   │   \u001b[0m\u001b[32m'id'\u001b[0m: \u001b[32m'QwnYaKLMA9eY0-kP2L2SmAk'\u001b[0m,\n",
       "\u001b[2;32m│   │   │   │   \u001b[0m\u001b[32m'service_tier'\u001b[0m: \u001b[3;35mNone\u001b[0m,\n",
       "\u001b[2;32m│   │   │   │   \u001b[0m\u001b[32m'finish_reason'\u001b[0m: \u001b[32m'stop'\u001b[0m,\n",
       "\u001b[2;32m│   │   │   │   \u001b[0m\u001b[32m'logprobs'\u001b[0m: \u001b[3;35mNone\u001b[0m\n",
       "\u001b[2;32m│   │   │   \u001b[0m\u001b[1m}\u001b[0m,\n",
       "\u001b[2;32m│   │   │   \u001b[0m\u001b[33mid\u001b[0m=\u001b[32m'run--1f56c980-b707-4958-bf18-fe34eaf7dc19-0'\u001b[0m,\n",
       "\u001b[2;32m│   │   │   \u001b[0m\u001b[33musage_metadata\u001b[0m=\u001b[1m{\u001b[0m\n",
       "\u001b[2;32m│   │   │   │   \u001b[0m\u001b[32m'input_tokens'\u001b[0m: \u001b[1;36m8\u001b[0m,\n",
       "\u001b[2;32m│   │   │   │   \u001b[0m\u001b[32m'output_tokens'\u001b[0m: \u001b[1;36m25\u001b[0m,\n",
       "\u001b[2;32m│   │   │   │   \u001b[0m\u001b[32m'total_tokens'\u001b[0m: \u001b[1;36m33\u001b[0m,\n",
       "\u001b[2;32m│   │   │   │   \u001b[0m\u001b[32m'input_token_details'\u001b[0m: \u001b[1m{\u001b[0m\u001b[1m}\u001b[0m,\n",
       "\u001b[2;32m│   │   │   │   \u001b[0m\u001b[32m'output_token_details'\u001b[0m: \u001b[1m{\u001b[0m\u001b[1m}\u001b[0m\n",
       "\u001b[2;32m│   │   │   \u001b[0m\u001b[1m}\u001b[0m\n",
       "\u001b[2;32m│   │   \u001b[0m\u001b[1m)\u001b[0m\n",
       "\u001b[2;32m│   \u001b[0m\u001b[1m]\u001b[0m\n",
       "\u001b[1m}\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "pprint(response)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "agentic-ai",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
